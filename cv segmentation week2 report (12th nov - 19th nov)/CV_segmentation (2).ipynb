{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f181ccb7-fde6-423b-b242-5501b673025e",
   "metadata": {},
   "source": [
    "# Checking file path of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a3b30d-a1c0-4647-bfdd-9cc73427ccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files: ['C:\\\\Users\\\\ISU\\\\cv_dataset\\\\image_data\\\\pat0_cropped_norm.nii', 'C:\\\\Users\\\\ISU\\\\cv_dataset\\\\image_data\\\\pat1_cropped_norm.nii', 'C:\\\\Users\\\\ISU\\\\cv_dataset\\\\image_data\\\\pat2_cropped_norm.nii']\n",
      "Segmentation files: ['C:\\\\Users\\\\ISU\\\\cv_dataset\\\\seg_data\\\\pat0_cropped_seg.nii', 'C:\\\\Users\\\\ISU\\\\cv_dataset\\\\seg_data\\\\pat1_cropped_seg.nii', 'C:\\\\Users\\\\ISU\\\\cv_dataset\\\\seg_data\\\\pat2_cropped_seg.nii']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Define paths to the folders\n",
    "image_folder = r\"C:\\Users\\ISU\\cv_dataset\\image_data\"\n",
    "segmentation_folder = r\"C:\\Users\\ISU\\cv_dataset\\seg_data\"\n",
    "\n",
    "# Get all files and sort them\n",
    "image_files = sorted(glob.glob(os.path.join(image_folder, \"*.nii\")))\n",
    "seg_files = sorted(glob.glob(os.path.join(segmentation_folder, \"*.nii\")))\n",
    "\n",
    "# Ensure they are matched correctly\n",
    "print(\"Image files:\", image_files)\n",
    "print(\"Segmentation files:\", seg_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2aa620-8ca5-4d4f-b64a-14f2049fc28d",
   "metadata": {},
   "source": [
    "# Model produces output file without padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b8b6fc-b6e8-4158-a634-e5fa462984c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files: ['C:\\\\Users\\\\ISU\\\\cv_dataset\\\\open_source_data\\\\preprocessed\\\\preprocessed_pat0_cropped_norm.nii', 'C:\\\\Users\\\\ISU\\\\cv_dataset\\\\open_source_data\\\\preprocessed\\\\preprocessed_pat1_cropped_norm.nii', 'C:\\\\Users\\\\ISU\\\\cv_dataset\\\\open_source_data\\\\preprocessed\\\\preprocessed_pat2_cropped_norm.nii']\n",
      "Segmentation files: ['C:\\\\Users\\\\ISU\\\\cv_dataset\\\\open_source_data\\\\preprocessed\\\\preprocessed_mask_pat0_cropped_seg.nii', 'C:\\\\Users\\\\ISU\\\\cv_dataset\\\\open_source_data\\\\preprocessed\\\\preprocessed_mask_pat1_cropped_seg.nii', 'C:\\\\Users\\\\ISU\\\\cv_dataset\\\\open_source_data\\\\preprocessed\\\\preprocessed_mask_pat2_cropped_seg.nii']\n",
      "Epoch 1/20, Loss: 0.7030\n",
      "Epoch 2/20, Loss: 0.6994\n",
      "Epoch 3/20, Loss: 0.6960\n",
      "Epoch 4/20, Loss: 0.6927\n",
      "Epoch 5/20, Loss: 0.6893\n",
      "Epoch 6/20, Loss: 0.6858\n",
      "Epoch 7/20, Loss: 0.6821\n",
      "Epoch 8/20, Loss: 0.6781\n",
      "Epoch 9/20, Loss: 0.6738\n",
      "Epoch 10/20, Loss: 0.6691\n",
      "Epoch 11/20, Loss: 0.6641\n",
      "Epoch 12/20, Loss: 0.6586\n",
      "Epoch 13/20, Loss: 0.6526\n",
      "Epoch 14/20, Loss: 0.6462\n",
      "Epoch 15/20, Loss: 0.6392\n",
      "Epoch 16/20, Loss: 0.6318\n",
      "Epoch 17/20, Loss: 0.6237\n",
      "Epoch 18/20, Loss: 0.6151\n",
      "Epoch 19/20, Loss: 0.6059\n",
      "Epoch 20/20, Loss: 0.5962\n",
      "Segmented heart saved at: patient_data\\segmented_heart.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Correct paths\n",
    "image_folder = r\"C:\\Users\\ISU\\cv_dataset\\open_source_data\\preprocessed\"\n",
    "segmentation_folder = r\"C:\\Users\\ISU\\cv_dataset\\open_source_data\\preprocessed\"\n",
    "\n",
    "# Find files using specific naming convention\n",
    "image_files = sorted(glob.glob(os.path.join(image_folder, \"preprocessed_pat*_cropped_norm.nii\")))\n",
    "seg_files = sorted(glob.glob(os.path.join(segmentation_folder, \"preprocessed_mask_pat*_cropped_seg.nii\")))\n",
    "\n",
    "print(\"Image files:\", image_files)\n",
    "print(\"Segmentation files:\", seg_files)\n",
    "\n",
    "# Directories for saving preprocessed data\n",
    "open_source_dir = \"open_source_data\"\n",
    "patient_dir = \"patient_data\"\n",
    "os.makedirs(open_source_dir, exist_ok=True)\n",
    "os.makedirs(patient_dir, exist_ok=True)\n",
    "\n",
    "# Configurations\n",
    "input_shape = (128, 128, 64)  # Resize dimensions\n",
    "batch_size = 2\n",
    "epochs = 20\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "### Step 1: Preprocess the Open-Source Dataset ###\n",
    "def preprocess_open_source_data(image_paths, seg_paths, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for img_path, seg_path in zip(image_paths, seg_paths):\n",
    "        # Load image and segmentation\n",
    "        img = nib.load(img_path).get_fdata()\n",
    "        seg = nib.load(seg_path).get_fdata()\n",
    "\n",
    "        # Convert segmentation to binary mask\n",
    "        binary_seg = np.isin(seg, [1, 2, 3, 4, 5, 6, 7, 8]).astype(np.uint8)\n",
    "\n",
    "        # Save preprocessed image and mask\n",
    "        nib.save(nib.Nifti1Image(img, np.eye(4)), os.path.join(output_dir, f\"preprocessed_{os.path.basename(img_path)}\"))\n",
    "        nib.save(nib.Nifti1Image(binary_seg, np.eye(4)), os.path.join(output_dir, f\"preprocessed_mask_{os.path.basename(seg_path)}\"))\n",
    "\n",
    "# Preprocess the open-source data\n",
    "preprocessed_data_dir = os.path.join(open_source_dir, \"preprocessed\")\n",
    "preprocess_open_source_data(image_files, seg_files, preprocessed_data_dir)\n",
    "\n",
    "### Step 2: Preprocess the Patient File ###\n",
    "def preprocess_patient_data(patient_img_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load and normalize patient image\n",
    "    patient_img = nib.load(patient_img_path).get_fdata()\n",
    "    patient_img = (patient_img - patient_img.min()) / (patient_img.max() - patient_img.min())\n",
    "\n",
    "    # Save preprocessed patient image\n",
    "    preprocessed_patient_path = os.path.join(output_dir, \"preprocessed_patient_image.nii.gz\")\n",
    "    nib.save(nib.Nifti1Image(patient_img, np.eye(4)), preprocessed_patient_path)\n",
    "\n",
    "    return preprocessed_patient_path\n",
    "\n",
    "# Example path for patient image\n",
    "patient_img_path = r\"C:\\Users\\ISU\\cv_dataset\\patient_image.nii\"  # Replace with actual path\n",
    "preprocessed_patient_path = preprocess_patient_data(patient_img_path, patient_dir)\n",
    "\n",
    "### Step 3: Define Dataset and Dataloader ###\n",
    "import scipy.ndimage\n",
    "\n",
    "class HeartDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def resize_3d(self, img, shape):\n",
    "        zoom_factors = [shape[0] / img.shape[0], shape[1] / img.shape[1], shape[2] / img.shape[2]]\n",
    "        resized_img = scipy.ndimage.zoom(img, zoom_factors, order=1)\n",
    "        return resized_img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = nib.load(self.image_paths[idx]).get_fdata()\n",
    "        mask = nib.load(self.mask_paths[idx]).get_fdata()\n",
    "\n",
    "        # Normalize image\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        # Resize the image and mask\n",
    "        img = self.resize_3d(img, input_shape)\n",
    "        mask = self.resize_3d(mask, input_shape)\n",
    "\n",
    "        # Convert to 3D format for PyTorch\n",
    "        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)  # Add channel dimension (1 for grayscale images)\n",
    "        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)  # Add channel dimension (1 for binary masks)\n",
    "\n",
    "        # Apply transform if available\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "\n",
    "# Load paths for preprocessed data\n",
    "image_paths = sorted(glob.glob(os.path.join(preprocessed_data_dir, \"preprocessed_pat*_cropped_norm.nii\")))\n",
    "mask_paths = sorted(glob.glob(os.path.join(preprocessed_data_dir, \"preprocessed_mask_pat*_cropped_seg.nii\")))\n",
    "\n",
    "# Split into training and validation\n",
    "train_img, val_img, train_mask, val_mask = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "])\n",
    "\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = HeartDataset(train_img, train_mask, transform=transform)\n",
    "val_dataset = HeartDataset(val_img, val_mask, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "### Step 4: Define U-Net Model ###\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(64, out_channels, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.upconv = nn.ConvTranspose3d(64, 64, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = self.encoder(x)\n",
    "        dec = self.upconv(enc)\n",
    "        dec = self.decoder(dec)\n",
    "        return dec\n",
    "\n",
    "# Initialize the model\n",
    "model = UNet3D(in_channels=1, out_channels=1).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        images, masks = batch\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"unet_heart_segmentation_3d.pth\")\n",
    "\n",
    "\n",
    "### Step 5: Evaluate on Patient File ###\n",
    "def segment_patient_image(model, patient_img_path, output_path):\n",
    "    model.eval()\n",
    "    patient_img = nib.load(patient_img_path).get_fdata()\n",
    "    patient_img = np.expand_dims(patient_img, axis=0)  # Add channel dimension\n",
    "    patient_img = np.expand_dims(patient_img, axis=0)  # Add batch dimension\n",
    "    patient_img = torch.tensor(patient_img, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(patient_img)\n",
    "        prediction = torch.sigmoid(prediction).cpu().numpy().squeeze()\n",
    "\n",
    "    # Save segmentation result\n",
    "    nib.save(nib.Nifti1Image(prediction, np.eye(4)), output_path)\n",
    "    print(f\"Segmented heart saved at: {output_path}\")\n",
    "\n",
    "segmented_heart_path = os.path.join(patient_dir, \"segmented_heart.nii.gz\")\n",
    "segment_patient_image(model, preprocessed_patient_path, segmented_heart_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499252f-02ae-4ebf-9ec9-45d0ffcdf868",
   "metadata": {},
   "source": [
    "# Model produces output file with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb353948-a80c-42d0-8342-32bfd3db935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images and 3 segmentations.\n",
      "Preprocessed open-source data saved in: C:\\Users\\ISU\\cv_dataset\\open_source_data\n",
      "Preprocessed patient image saved in: C:\\Users\\ISU\\cv_dataset\\patient_data\\preprocessed_patient_image.nii.gz\n",
      "Epoch 1/20, Loss: 0.6961\n",
      "Epoch 2/20, Loss: 0.6939\n",
      "Epoch 3/20, Loss: 0.6917\n",
      "Epoch 4/20, Loss: 0.6895\n",
      "Epoch 5/20, Loss: 0.6873\n",
      "Epoch 6/20, Loss: 0.6850\n",
      "Epoch 7/20, Loss: 0.6826\n",
      "Epoch 8/20, Loss: 0.6800\n",
      "Epoch 9/20, Loss: 0.6772\n",
      "Epoch 10/20, Loss: 0.6741\n",
      "Epoch 11/20, Loss: 0.6707\n",
      "Epoch 12/20, Loss: 0.6670\n",
      "Epoch 13/20, Loss: 0.6628\n",
      "Epoch 14/20, Loss: 0.6582\n",
      "Epoch 15/20, Loss: 0.6530\n",
      "Epoch 16/20, Loss: 0.6474\n",
      "Epoch 17/20, Loss: 0.6412\n",
      "Epoch 18/20, Loss: 0.6345\n",
      "Epoch 19/20, Loss: 0.6273\n",
      "Epoch 20/20, Loss: 0.6194\n",
      "Segmented heart saved at: C:\\Users\\ISU\\cv_dataset\\patient_data\\segmented_heart.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import scipy.ndimage\n",
    "\n",
    "# Set base directories\n",
    "BASE_DIR = r\"C:\\Users\\ISU\\cv_dataset\"\n",
    "IMAGE_FOLDER = os.path.join(BASE_DIR, \"open_source_data\", \"preprocessed\")\n",
    "SEGMENTATION_FOLDER = IMAGE_FOLDER  # Assuming images and masks are in the same folder\n",
    "PATIENT_IMAGE_PATH = os.path.join(BASE_DIR, \"patient_image.nii\")  # Replace with actual patient file\n",
    "\n",
    "# File matching patterns\n",
    "IMAGE_PATTERN = \"preprocessed_pat*_cropped_norm.nii\"\n",
    "MASK_PATTERN = \"preprocessed_mask_pat*_cropped_seg.nii\"\n",
    "\n",
    "# Get image and segmentation file paths\n",
    "image_files = sorted(glob.glob(os.path.join(IMAGE_FOLDER, IMAGE_PATTERN)))\n",
    "segmentation_files = sorted(glob.glob(os.path.join(SEGMENTATION_FOLDER, MASK_PATTERN)))\n",
    "\n",
    "if not image_files or not segmentation_files:\n",
    "    raise FileNotFoundError(\"No image or segmentation files found. Please check the paths or file naming conventions.\")\n",
    "\n",
    "print(f\"Found {len(image_files)} images and {len(segmentation_files)} segmentations.\")\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR_OPEN_SOURCE = os.path.join(BASE_DIR, \"open_source_data\")\n",
    "OUTPUT_DIR_PATIENT = os.path.join(BASE_DIR, \"patient_data\")\n",
    "os.makedirs(OUTPUT_DIR_OPEN_SOURCE, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_PATIENT, exist_ok=True)\n",
    "\n",
    "# Configurations\n",
    "INPUT_SHAPE = (128, 128, 64)  # Resize dimensions\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "### Step 1: Preprocess Open-Source Data ###\n",
    "def preprocess_open_source_data(image_paths, mask_paths, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for img_path, seg_path in zip(image_paths, mask_paths):\n",
    "        # Load image and segmentation\n",
    "        img = nib.load(img_path).get_fdata()\n",
    "        seg = nib.load(seg_path).get_fdata()\n",
    "\n",
    "        # Convert segmentation to binary mask\n",
    "        binary_seg = np.isin(seg, range(1, 9)).astype(np.uint8)  # Map values 1-8 to binary mask\n",
    "\n",
    "        # Save preprocessed data\n",
    "        img_name = f\"preprocessed_{os.path.basename(img_path)}\"\n",
    "        seg_name = f\"preprocessed_mask_{os.path.basename(seg_path)}\"\n",
    "        nib.save(nib.Nifti1Image(img, np.eye(4)), os.path.join(output_dir, img_name))\n",
    "        nib.save(nib.Nifti1Image(binary_seg, np.eye(4)), os.path.join(output_dir, seg_name))\n",
    "\n",
    "    print(f\"Preprocessed open-source data saved in: {output_dir}\")\n",
    "\n",
    "\n",
    "preprocess_open_source_data(image_files, segmentation_files, OUTPUT_DIR_OPEN_SOURCE)\n",
    "\n",
    "\n",
    "### Step 2: Preprocess Patient Image ###\n",
    "def preprocess_patient_data(patient_img_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load and normalize patient image\n",
    "    patient_img = nib.load(patient_img_path).get_fdata()\n",
    "    patient_img = (patient_img - patient_img.min()) / (patient_img.max() - patient_img.min())\n",
    "\n",
    "    # Save preprocessed patient image\n",
    "    preprocessed_patient_path = os.path.join(output_dir, \"preprocessed_patient_image.nii.gz\")\n",
    "    nib.save(nib.Nifti1Image(patient_img, np.eye(4)), preprocessed_patient_path)\n",
    "\n",
    "    print(f\"Preprocessed patient image saved in: {preprocessed_patient_path}\")\n",
    "    return preprocessed_patient_path\n",
    "\n",
    "\n",
    "preprocessed_patient_path = preprocess_patient_data(PATIENT_IMAGE_PATH, OUTPUT_DIR_PATIENT)\n",
    "\n",
    "\n",
    "### Step 3: Dataset Definition ###\n",
    "class HeartDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def resize_3d(self, img, shape):\n",
    "        zoom_factors = [shape[i] / img.shape[i] for i in range(3)]\n",
    "        return scipy.ndimage.zoom(img, zoom_factors, order=1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = nib.load(self.image_paths[idx]).get_fdata()\n",
    "        mask = nib.load(self.mask_paths[idx]).get_fdata()\n",
    "\n",
    "        # Normalize image\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "        # Resize the image and mask\n",
    "        img = self.resize_3d(img, INPUT_SHAPE)\n",
    "        mask = self.resize_3d(mask, INPUT_SHAPE)\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_img, val_img, train_mask, val_mask = train_test_split(image_files, segmentation_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = HeartDataset(train_img, train_mask)\n",
    "val_dataset = HeartDataset(val_img, val_mask)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "### Step 4: Define U-Net Model ###\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(64, out_channels, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.upconv = nn.ConvTranspose3d(64, 64, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = self.encoder(x)\n",
    "        dec = self.upconv(enc)\n",
    "        dec = self.decoder(dec)\n",
    "        return dec\n",
    "\n",
    "\n",
    "model = UNet3D(in_channels=1, out_channels=1).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(BASE_DIR, \"unet_heart_segmentation_3d.pth\"))\n",
    "\n",
    "\n",
    "### Step 5: Segment Patient Image ###\n",
    "def segment_patient_image(model, patient_img_path, output_path):\n",
    "    model.eval()\n",
    "    patient_img = nib.load(patient_img_path).get_fdata()\n",
    "    patient_img = np.expand_dims(patient_img, axis=(0, 1))  # Add channel and batch dimensions\n",
    "    patient_img = torch.tensor(patient_img, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(patient_img)\n",
    "        prediction = torch.sigmoid(prediction).cpu().numpy().squeeze()\n",
    "\n",
    "    nib.save(nib.Nifti1Image(prediction, np.eye(4)), output_path)\n",
    "    print(f\"Segmented heart saved at: {output_path}\")\n",
    "\n",
    "\n",
    "segmented_heart_path = os.path.join(OUTPUT_DIR_PATIENT, \"segmented_heart.nii.gz\")\n",
    "segment_patient_image(model, preprocessed_patient_path, segmented_heart_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90f6dec-a6bc-44a7-b7ee-bf6b989cd3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
